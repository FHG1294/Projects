{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from io import StringIO\n",
    "from io import StringIO\n",
    "import tarfile\n",
    "from sklearn.model_selection import train_test_split as split_sk\n",
    "import surprise\n",
    "from surprise import Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "#from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy, Dataset, SVD\n",
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfit = pd.read_csv('jester_items.csv')\n",
    "dfrt = pd.read_csv('jester_ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1761439 entries, 0 to 1761438\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Dtype  \n",
      "---  ------    -----  \n",
      " 0   userId    int64  \n",
      " 1   jokeId    int64  \n",
      " 2   rating    float64\n",
      " 3   jokeText  object \n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 67.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>jokeId</th>\n",
       "      <th>rating</th>\n",
       "      <th>jokeText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.688</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>-5.812</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6.906</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  jokeId  rating                                           jokeText\n",
       "0       1       5   0.219  Q.\\tWhat's O. J. Simpson's Internet address? \\...\n",
       "1       2       5  -9.688  Q.\\tWhat's O. J. Simpson's Internet address? \\...\n",
       "2       3       5  -9.844  Q.\\tWhat's O. J. Simpson's Internet address? \\...\n",
       "3       4       5  -5.812  Q.\\tWhat's O. J. Simpson's Internet address? \\...\n",
       "4       5       5   6.906  Q.\\tWhat's O. J. Simpson's Internet address? \\..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(dfrt, dfit, on='jokeId')\n",
    "#merged = merged.reset_index(drop=True)\n",
    "#merged[\"rating\"] = merged[\"rating\"].astype(\"float16\")\n",
    "#merged[\"jokeId\"] = merged[\"jokeId\"].astype(\"int16\")\n",
    "#merged[\"userId\"] = merged[\"userId\"].astype(\"int16\")\n",
    "#merged[\"jokeText\"] = merged[\"jokeText\"].astype(\"str\")\n",
    "merged.info()\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1761439, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franh\\AppData\\Local\\Temp\\ipykernel_22456\\1532120522.py:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  sns.heatmap(merged.corr(), annot = True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(merged.corr(), annot = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>3<span style='color:#F76251'>|</span> Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>jokeId</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>...</th>\n",
       "      <th>141</th>\n",
       "      <th>142</th>\n",
       "      <th>143</th>\n",
       "      <th>144</th>\n",
       "      <th>145</th>\n",
       "      <th>146</th>\n",
       "      <th>147</th>\n",
       "      <th>148</th>\n",
       "      <th>149</th>\n",
       "      <th>150</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.219</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-6.781</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-9.656</td>\n",
       "      <td>-9.031</td>\n",
       "      <td>-7.469</td>\n",
       "      <td>-8.719</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.688</td>\n",
       "      <td>9.938</td>\n",
       "      <td>9.531</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.406</td>\n",
       "      <td>3.719</td>\n",
       "      <td>9.656</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-9.562</td>\n",
       "      <td>-9.125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-9.844</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>-7.219</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>-9.938</td>\n",
       "      <td>-9.969</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-9.781</td>\n",
       "      <td>-6.844</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.812</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>-4.906</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.906</td>\n",
       "      <td>4.750</td>\n",
       "      <td>-5.906</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-4.031</td>\n",
       "      <td>3.875</td>\n",
       "      <td>6.219</td>\n",
       "      <td>5.656</td>\n",
       "      <td>6.094</td>\n",
       "      <td>5.406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "jokeId    5      7      8      13     15     16     17     18     19     20   \\\n",
       "userId                                                                         \n",
       "1       0.219 -9.281 -9.281 -6.781  0.875 -9.656 -9.031 -7.469 -8.719 -9.156   \n",
       "2      -9.688  9.938  9.531  9.938  0.406  3.719  9.656 -2.688 -9.562 -9.125   \n",
       "3      -9.844 -9.844 -7.219 -2.031 -9.938 -9.969 -9.875 -9.812 -9.781 -6.844   \n",
       "4      -5.812 -4.500 -4.906  0.000  0.000  0.000  0.000  0.000  0.000  0.000   \n",
       "5       6.906  4.750 -5.906 -0.406 -4.031  3.875  6.219  5.656  6.094  5.406   \n",
       "\n",
       "jokeId  ...  141  142  143  144  145  146  147  148  149  150  \n",
       "userId  ...                                                    \n",
       "1       ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2       ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3       ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4       ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5       ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot the dataframe to create a matrix\n",
    "matrix = merged.pivot(index = 'userId', columns = 'jokeId', values = 'rating').fillna(0)\n",
    "matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "# CReating a spare matrix\n",
    "nmatr = csr_matrix(matrix.values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged[['userId', 'jokeId', 'rating']]\n",
    "y = merged['jokeText']\n",
    "\n",
    "# Split data into 80% training set and 20% test set\n",
    "X_train, X_test, y_train, y_test = split_sk(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split training data into 75% training set and 25% validation set\n",
    "X_train, X_val, y_train, y_val = split_sk(X_train, y_train, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sparse matrix for training set\n",
    "train_matrix = pd.pivot_table(X_train, values='rating', index='userId', columns='jokeId')\n",
    "train_matrix = csr_matrix(train_matrix.fillna(0))\n",
    "\n",
    "# Create sparse matrix for validation set\n",
    "val_matrix = pd.pivot_table(X_val, values='rating', index='userId', columns='jokeId')\n",
    "val_matrix = csr_matrix(val_matrix.fillna(0))\n",
    "\n",
    "# Create sparse matrix for test set\n",
    "test_matrix = pd.pivot_table(X_test, values='rating', index='userId', columns='jokeId')\n",
    "test_matrix = csr_matrix(test_matrix.fillna(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Train the model\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=5)\n",
    "model_knn.fit(train_matrix)\n",
    "\n",
    "# Find k-neighbors for each user in the validation set\n",
    "distances, indices = model_knn.kneighbors(val_matrix, n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of 5 nearest neighbors: [[  135 47924 57918 27260 54506]]\n",
      "Distances to 5 nearest neighbors: [[0.46142869 0.48331927 0.49795378 0.50140056 0.509458  ]]\n"
     ]
    }
   ],
   "source": [
    "print('Indices of 5 nearest neighbors:', indices[:1])\n",
    "print('Distances to 5 nearest neighbors:', distances[:1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'algorithm': 'brute', 'leaf_size': 10, 'n_neighbors': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [10, 20, 30],\n",
    "    'algorithm': ['brute', 'kd_tree'],\n",
    "    'leaf_size': [10, 20, 30],\n",
    "}\n",
    "\n",
    "# Define a custom scorer that computes the mean squared error\n",
    "def mse_scorer(estimator, X, y):\n",
    "    distances, indices = estimator.kneighbors(X, n_neighbors=20)\n",
    "    y_pred = []\n",
    "    for i in range(len(indices)):\n",
    "        jokes = indices[i]\n",
    "        ratings = train_matrix[jokes, :].toarray()[0]\n",
    "        y_pred.append(np.mean(ratings[ratings != 0]))\n",
    "    return mean_squared_error(y, y_pred)\n",
    "\n",
    "# Create the k-NN model\n",
    "model_knn = NearestNeighbors(metric='cosine')\n",
    "\n",
    "# Create the GridSearchCV object with the custom scorer\n",
    "grid_search = GridSearchCV(model_knn, param_grid, cv=5, scoring=make_scorer(mse_scorer))\n",
    "\n",
    "# Fit the GridSearchCV object on the training set\n",
    "grid_search.fit(train_matrix)\n",
    "\n",
    "# Print the best parameters found\n",
    "print(\"Best parameters:\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [352288, 52659]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[129], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m     ratings \u001b[39m=\u001b[39m train_matrix[jokes, :]\u001b[39m.\u001b[39mtoarray()[\u001b[39m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m     y_pred\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39mmean(ratings[ratings \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m]))\n\u001b[1;32m----> 9\u001b[0m mse \u001b[39m=\u001b[39m mean_squared_error(y_test, y_pred)\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest set MSE:\u001b[39m\u001b[39m\"\u001b[39m, mse)\n",
      "File \u001b[1;32mc:\\Users\\franh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[0;32m    383\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    384\u001b[0m ):\n\u001b[0;32m    385\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \n\u001b[0;32m    387\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    443\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    444\u001b[0m     )\n\u001b[0;32m    445\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    446\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\franh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32mc:\\Users\\franh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    400\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [352288, 52659]"
     ]
    }
   ],
   "source": [
    "# Evaluate the model performance on the test set using the best parameters found\n",
    "best_model = grid_search.best_estimator_\n",
    "distances, indices = best_model.kneighbors(test_matrix, n_neighbors=20)\n",
    "y_pred = []\n",
    "for i in range(len(indices)):\n",
    "    jokes = indices[i]\n",
    "    ratings = train_matrix[jokes, :].toarray()[0]\n",
    "    y_pred.append(np.mean(ratings[ratings != 0]))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test set MSE:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prueba con codigo de chatgpt para encontrar similitudes entre users, seguido de distancia y 3 peliculas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors of user 135\n",
      "Neighbor 2 - UserId: 3053 - Distance: 0.4916632629173475 - Jokes: [\"How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n\"\n",
      " 'Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n'\n",
      " 'They asked the Japanese visitor if they have elections in his\\ncountry.  \\n\"Every Morning\" he answers.\\n']\n",
      "Neighbor 3 - UserId: 28304 - Distance: 0.5108788972089806 - Jokes: [\"How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n\"\n",
      " 'Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n'\n",
      " 'They asked the Japanese visitor if they have elections in his\\ncountry.  \\n\"Every Morning\" he answers.\\n']\n",
      "Neighbor 4 - UserId: 426 - Distance: 0.5287445488721079 - Jokes: [\"Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n\"\n",
      " \"How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n\"\n",
      " 'Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n']\n",
      "Neighbor 5 - UserId: 421 - Distance: 0.5681635261031197 - Jokes: [\"Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n\"\n",
      " \"How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n\"\n",
      " 'Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n']\n"
     ]
    }
   ],
   "source": [
    "# create a sparse matrix using userID as rows, movie_id as columns, and ratings as values\n",
    "sparse_matrix = csr_matrix((merged[\"rating\"], (merged[\"userId\"], merged[\"jokeId\"])))\n",
    "\n",
    "# create a kNN model using cosine similarity\n",
    "modelpt = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\", n_neighbors=5)\n",
    "\n",
    "# fit the model to the sparse matrix\n",
    "modelpt.fit(sparse_matrix)\n",
    "\n",
    "# select a user ID for which to find the nearest neighbors\n",
    "query_user = 135\n",
    "\n",
    "# find the indices and distances to the 10 nearest neighbors of the query user\n",
    "distances, indices = modelpt.kneighbors(sparse_matrix[query_user], n_neighbors=5)\n",
    "\n",
    "# print the titles of the movies that the nearest neighbors rated\n",
    "print(\"Nearest neighbors of user\", query_user)\n",
    "for i in range(1, len(distances[0])): # The loop starts at 1 because the neighbor #1 is going to be the same user as selected in the query\n",
    "    neighbor_user = indices[0][i]\n",
    "    neighbor_distance = distances[0][i]\n",
    "    neighbor_movies = merged.loc[merged[\"userId\"] == neighbor_user][\"jokeText\"].values[:3] # limit to 3 movies as example \n",
    "    print(\"Neighbor\", i+1, \"- UserId:\", neighbor_user, \"- Distance:\", neighbor_distance, \"- Jokes:\", neighbor_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD with Surprise pckg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Performing SVD in a smaller dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged['userId'] = merged['userId'].astype(int) \n",
    "merged['jokeId'] = merged['jokeId'].astype(int)\n",
    "merged['rating'] = merged['rating'].astype(float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming df into a Surprise specific data structure\n",
    "reader = surprise.Reader(rating_scale=(1, 5))\n",
    "svd_data = surprise.Dataset.load_from_df(merged[['userId', 'jokeId', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.7843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.784262081488439"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise.model_selection import train_test_split as split_surprise\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = split_surprise(svd_data, test_size=0.25)\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Train the algorithm on the trainset, and predict ratings for the testset\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "# Then compute RMSE\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE of 0.9169 is too high which menas that the model is not accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    4.7815  4.7805  4.7754  4.7850  4.7827  4.7810  0.0032  \n",
      "MAE (testset)     3.7451  3.7432  3.7364  3.7505  3.7487  3.7448  0.0049  \n",
      "Fit time          19.21   18.68   19.75   20.43   17.91   19.19   0.87    \n",
      "Test time         3.04    3.14    3.18    3.90    3.08    3.27    0.32    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([4.78154473, 4.78045803, 4.77539661, 4.78499974, 4.78272823]),\n",
       " 'test_mae': array([3.74511646, 3.74321482, 3.73644876, 3.75053813, 3.74873793]),\n",
       " 'fit_time': (19.210875511169434,\n",
       "  18.680373430252075,\n",
       "  19.745484828948975,\n",
       "  20.432854175567627,\n",
       "  17.905160665512085),\n",
       " 'test_time': (3.0361342430114746,\n",
       "  3.142449378967285,\n",
       "  3.1804862022399902,\n",
       "  3.8995702266693115,\n",
       "  3.0834622383117676)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run 5-fold cross-validation and print results on based on the extracted final dataset\n",
    "cross_validate(algo, svd_data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD (training the model on the whole dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1206400d990>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "svd_algo = surprise.SVD()\n",
    "trainset = svd_data.build_full_trainset()\n",
    "svd_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['If pro- is the opposite of con- then congress must be the opposite\\nof progress.\\n', 'A lady bought a new Lexus. It cost a bundle. Two days later, she brought it back, complaining that the radio was not working. \"Madam,\" said the sales manager, \"the audio system in this car is completely automatic. All you need to do is tell it what you want to listen to, and you will hear exactly that!\" She drove out, somewhat amazed and a little confused. She looked at the radio and said, \"Nelson.\" The radio responded, \"Ricky or Willie?\" She was astounded. If she wanted Beethoven, that\\'s what she got. If she wanted Nat King Cole, she got it. She was stopped at a traffic light enjoying \"On the Road Again\" when the light turned green and she pulled out. Suddenly an enormous sports utility vehicle coming from the street she was crossing sped toward her, obviously not paying attention to the light. She swerved and narrowly missed a collision. \"Idiot!\" she yelled and, from the radio, \"Ladies and gentlemen, the President of the United States.\"', 'Judy was having trouble with her computer, so she called Tony, the computer guy, over to her desk. Tony clicked a couple buttons and solved the problem. As he was walking away, Judy called after him, \"So, what was wrong?\" And he replied, \"It was an ID Ten T Error.\" A puzzled expression ran riot over Judy\\'s face. \"An ID Ten T Error? What\\'s that...in case I need to fix it again?\" He gave her a grin...\"Haven\\'t you ever heard of an ID Ten T Error before?\" \"No,\" replied Judy. \"Write it down,\" he said, \"and I think you\\'ll figure it out.\" (She wrote...) I D 1 0 T', 'In a Veteran\\'s Day speech, President Bush vowed, \"We will finish the mission. Period.\" Afterwards, he was advised that he doesn\\'t have to read the punctuation marks.', 'A drunk staggers into a Catholic Church, enters a confessional booth, sits down, but says nothing. The Priest coughs a few times to get his attention but the drunk just sits there. Finally, the Priest pounds three times on the wall. The drunk mumbles, \"Ain\\'t no use knockin, there\\'s no paper on this side either.\"']\n"
     ]
    }
   ],
   "source": [
    "# Recommending 5 movies to x user\n",
    "x = 30878 # userID number\n",
    "k = 5 # Number of movies that are going to be recommended\n",
    "\n",
    "# recommend top-k movies for a given user\n",
    "user_items = trainset.ur[trainset.to_inner_uid(x)]\n",
    "not_watched = [item_id for item_id in trainset.all_items() if item_id not in user_items]\n",
    "predictions = [svd_algo.predict(x, item_id) for item_id in not_watched]\n",
    "top_k_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:k]\n",
    "recommended_titles = [merged[merged['jokeId'] == pred.iid]['jokeText'].iloc[0] for pred in top_k_predictions]\n",
    "\n",
    "# print the recommended movie titles\n",
    "print(recommended_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune algorithm parameters with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the average RMSE and MAE over a 3-fold cross-validation procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GridSearchCV.__init__() got an unexpected keyword argument 'measures'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m param_grid \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mn_epochs\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m5\u001b[39m, \u001b[39m10\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mlr_all\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.002\u001b[39m, \u001b[39m0.005\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mreg_all\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m0.4\u001b[39m, \u001b[39m0.6\u001b[39m]}\n\u001b[1;32m----> 2\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(SVD, param_grid, measures\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mrmse\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmae\u001b[39;49m\u001b[39m\"\u001b[39;49m], cv\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m gs\u001b[39m.\u001b[39mfit(svd_data)\n\u001b[0;32m      6\u001b[0m \u001b[39m# best RMSE score\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: GridSearchCV.__init__() got an unexpected keyword argument 'measures'"
     ]
    }
   ],
   "source": [
    "param_grid = {\"n_epochs\": [5, 10], \"lr_all\": [0.002, 0.005], \"reg_all\": [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"rmse\", \"mae\"], cv=3)\n",
    "\n",
    "gs.fit(svd_data)\n",
    "\n",
    "# best RMSE score\n",
    "print(gs.best_score[\"rmse\"])\n",
    "\n",
    "# combination of parameters that gave the best RMSE score\n",
    "print(gs.best_params[\"rmse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x25312e46680>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can now use the algorithm that yields the best rmse:\n",
    "best_algo = gs.best_estimator[\"rmse\"]\n",
    "best_algo.fit(svd_data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using best model for recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alias: Season 1', 'Inu-Yasha: The Movie 3: Swords of an Honorable Ruler', 'Six Feet Under: Season 4', 'Harakiri', 'As Time Goes By: Series 8']\n"
     ]
    }
   ],
   "source": [
    "# Recommending 5 movies to x user\n",
    "x = 30878 # userID number\n",
    "k = 5 # Number of movies that are going to be recommended\n",
    "\n",
    "# recommend top-k movies for a given user\n",
    "user_items = trainset.ur[trainset.to_inner_uid(x)]\n",
    "not_watched = [item_id for item_id in trainset.all_items() if item_id not in user_items]\n",
    "predictions = [best_algo.predict(x, item_id) for item_id in not_watched]\n",
    "top_k_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:k]\n",
    "recommended_titles = [final_df[final_df['movie_id'] == pred.iid]['title'].iloc[0] for pred in top_k_predictions]\n",
    "\n",
    "# print the recommended movie titles\n",
    "print(recommended_titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
